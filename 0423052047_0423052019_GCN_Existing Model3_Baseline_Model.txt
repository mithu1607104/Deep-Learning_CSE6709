import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from tensorflow.keras.utils import to_categorical
import networkx as nx
from spektral.layers import GCNConv
from spektral.data import Dataset, Graph
from spektral.models import GCN
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, Dropout
import matplotlib.pyplot as plt
import seaborn as sns

# Step 1: Load Dataset
file_path = '/content/drive/My Drive/BUET/Deep learning/Dataset_with_named_clusters.csv'  # Update the file path
df = pd.read_csv(file_path)

# Step 2: Preprocess the Sequence Data
def one_hot_encode_sequence(sequences, max_length, vocab="ACDEFGHIKLMNPQRSTVWY"):
    vocab_dict = {char: idx for idx, char in enumerate(vocab)}
    encoded = np.zeros((len(sequences), max_length, len(vocab)))
    for i, seq in enumerate(sequences):
        for j, char in enumerate(seq[:max_length]):
            if char in vocab_dict:
                encoded[i, j, vocab_dict[char]] = 1
    return encoded

max_sequence_length = 60
vocab = "ACDEFGHIKLMNPQRSTVWY"
X_sequences = one_hot_encode_sequence(df['Sequence'].fillna(""), max_length=max_sequence_length, vocab=vocab)

# Flatten the sequence features to use as node features
node_features = X_sequences.reshape(X_sequences.shape[0], -1)

# Encode target variable
label_encoder = LabelEncoder()
y_labels = label_encoder.fit_transform(df['Cluster_Name'])
y_categorical = to_categorical(y_labels)

# Step 3: Create a Graph Structure
# For simplicity, create a random graph. Replace this with a real adjacency matrix if available.
n_nodes = len(node_features)
adj_matrix = np.random.rand(n_nodes, n_nodes) > 0.95  # Random adjacency for demonstration
adj_matrix = adj_matrix.astype(float)

# Normalize the adjacency matrix
adj_matrix = adj_matrix + np.eye(n_nodes)  # Add self-loops
row_sums = adj_matrix.sum(axis=1)
adj_matrix = adj_matrix / row_sums[:, np.newaxis]

# Step 4: Split Data into Train and Test Sets
X_train, X_test, y_train, y_test, train_idx, test_idx = train_test_split(
    node_features, y_categorical, np.arange(len(node_features)), test_size=0.2, random_state=42
)

# Step 5: Define GCN Model
class GCNModel(Model):
    def __init__(self, n_classes):
        super().__init__()
        self.gcn1 = GCNConv(64, activation="relu")
        self.gcn2 = GCNConv(n_classes, activation="softmax")

    def call(self, inputs):
        x, a = inputs
        x = self.gcn1([x, a])
        x = self.gcn2([x, a])
        return x

# Initialize model
n_classes = y_categorical.shape[1]
model = GCNModel(n_classes)

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Step 6: Train the GCN Model
X_train_features = node_features[train_idx]
A_train = adj_matrix[train_idx][:, train_idx]
y_train_labels = y_categorical[train_idx]

X_test_features = node_features[test_idx]
A_test = adj_matrix[test_idx][:, test_idx]
y_test_labels = y_categorical[test_idx]

history = model.fit(
    x=[X_train_features, A_train],
    y=y_train_labels,
    validation_data=([X_test_features, A_test], y_test_labels),
    epochs=100,
    batch_size=32,
    verbose=1
)

# Step 7: Evaluate the Model
y_pred = model.predict([X_test_features, A_test])
y_pred_labels = np.argmax(y_pred, axis=1)
y_test_true_labels = np.argmax(y_test_labels, axis=1)

accuracy = accuracy_score(y_test_true_labels, y_pred_labels)
print(f"Test Accuracy: {accuracy}")
print("\nClassification Report:")
print(classification_report(y_test_true_labels, y_pred_labels, target_names=label_encoder.classes_))

# Step 8: Confusion Matrix
conf_matrix = confusion_matrix(y_test_true_labels, y_pred_labels)
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()

# Step 9: Plot Training History
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()
