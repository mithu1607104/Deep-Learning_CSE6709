import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler, StandardScaler
from sklearn.decomposition import PCA
from sklearn.utils.class_weight import compute_class_weight
import matplotlib.pyplot as plt
import seaborn as sns

# Step 1: Load Dataset
file_path = '/content/drive/My Drive/BUET/Deep learning/Dataset_with_named_clusters.csv'  # Update the file path
df = pd.read_csv(file_path)

# Step 2: Preprocess the Data
# Use GO_Description as text features and encode categorical features
df['GO_Description'] = df['GO_Description'].fillna("")

# Step 3: Text Feature Extraction using TF-IDF
tfidf_vectorizer = TfidfVectorizer(max_features=2000)  # Increase max features to capture more details
X_text_features = tfidf_vectorizer.fit_transform(df['GO_Description']).toarray()

# Process Protein Sequences using one-hot encoding
def one_hot_encode_sequence(sequences, max_length, vocab="ACDEFGHIKLMNPQRSTVWY"):
    vocab_dict = {char: idx for idx, char in enumerate(vocab)}
    encoded = np.zeros((len(sequences), max_length, len(vocab)))
    for i, seq in enumerate(sequences):
        for j, char in enumerate(seq[:max_length]):
            if char in vocab_dict:
                encoded[i, j, vocab_dict[char]] = 1
    return encoded.reshape(len(sequences), -1)  # Flatten for compatibility with SVM

max_sequence_length = 60  # Use max sequence length from the dataset
X_sequence_features = one_hot_encode_sequence(df['Sequence'].fillna(""), max_length=max_sequence_length)

# Process Motif Extraction and EvidenceCode
motif_encoder = OneHotEncoder()
X_motif = motif_encoder.fit_transform(df['Motif Extraction'].fillna("Unknown").values.reshape(-1, 1)).toarray()

evidence_scaler = StandardScaler()  # Use StandardScaler for numerical features
X_evidence = evidence_scaler.fit_transform(df['EvidenceCode'].values.reshape(-1, 1))

# Combine All Features
X_features = np.hstack([X_text_features, X_sequence_features, X_motif, X_evidence])

# Step 4: Dimensionality Reduction using PCA
pca = PCA(n_components=500)  # Reduce to 500 dimensions
X_features_reduced = pca.fit_transform(X_features)

# Step 5: Encode Target Variable
label_encoder = LabelEncoder()
y_labels = label_encoder.fit_transform(df['Cluster_Name'])

# Step 6: Split Data into Train and Test Sets
X_train, X_test, y_train, y_test = train_test_split(X_features_reduced, y_labels, test_size=0.2, random_state=42)

# Step 7: Handle Class Imbalance with Class Weights
class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)
class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}

# Step 8: Train the SVM Model with Class Weights
svm_model = SVC(kernel='rbf', C=10, gamma=0.01, probability=True, class_weight=class_weight_dict)  # Use RBF kernel
svm_model.fit(X_train, y_train)

# Step 9: Evaluate the Model
y_pred = svm_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Test Accuracy: {accuracy}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# Step 10: Confusion Matrix
conf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()

# Step 11: Optional: Hyperparameter Tuning
from sklearn.model_selection import GridSearchCV

param_grid = {
    'C': [1, 10, 100],
    'gamma': [0.001, 0.01, 0.1],
    'kernel': ['rbf']
}

grid_search = GridSearchCV(SVC(probability=True, class_weight=class_weight_dict), param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)

print(f"Best Parameters: {grid_search.best_params_}")
best_model = grid_search.best_estimator_

# Evaluate the Best Model
y_best_pred = best_model.predict(X_test)
best_accuracy = accuracy_score(y_test, y_best_pred)
print(f"Best Model Test Accuracy: {best_accuracy}")

# Visualizing Accuracy for Different Parameters
results = grid_search.cv_results_
param_combinations = range(len(results['mean_test_score']))

plt.figure(figsize=(10, 6))
plt.plot(param_combinations, results['mean_test_score'], marker='o', label="Mean Test Score")
plt.xticks(param_combinations, [f"C={param['C']}, Î³={param['gamma']}" for param in results['params']], rotation=45)
plt.xlabel("Parameter Combinations")
plt.ylabel("Accuracy")
plt.title("Hyperparameter Tuning - Accuracy by Parameter Combination")
plt.legend()
plt.tight_layout()
plt.show()